{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrames II\n",
    "\n",
    "\n",
    "### Programming for Data Science\n",
    "### Last Updated: Jan 15, 2023\n",
    "---  \n",
    "\n",
    "\n",
    "### PREREQUISITES\n",
    "- variables\n",
    "- data types\n",
    "- operators\n",
    "- list comprehensions (not essential)\n",
    "- numpy arrays (not essential)\n",
    "- pandas DataFrames I\n",
    "\n",
    "\n",
    "### SOURCES \n",
    "- ten minutes to pandas  \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "\n",
    "\n",
    "- pivot_table()  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html\n",
    "\n",
    "\n",
    "- concat()  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
    "\n",
    "\n",
    "- merge()  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "\n",
    "\n",
    "- get_dummies()  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
    "\n",
    "\n",
    "\n",
    "### OBJECTIVES\n",
    "- Introduce more advanced pandas dataframe operations for data munging\n",
    " \n",
    "\n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- DataFrame\n",
    "- apply()\n",
    "- aggregation using split-apply-combine\n",
    "- pivot_table()\n",
    "- groupby()\n",
    "- concat()\n",
    "- merging/joining dataframes with merge(), concat()\n",
    "- reshaping data\n",
    "- dummy coding categorical data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Pandas DataFrame Functionality\n",
    "\n",
    "Pandas DataFrames I covered creating, modifying, and subsetting DataFrames, among other topics.  \n",
    "These notes will demonstrate further methods for data munging and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. `apply()`\n",
    "\n",
    "Apply a transformation to each record. Uses a `lambda` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['sepal_len_sq'] = iris.sepal_length.apply(lambda x: x**2)\n",
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation involving multiple columns. Uses `axis=1` to access columns.  \n",
    "Compute average of `sepal_length`, `sepal_width`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['sepal_len_wid_avg'] = iris[['sepal_length','sepal_width']].apply(lambda x: (x.sepal_length+x.sepal_width)/2, axis=1)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use `apply()` to append a new column that is the minimum of (petal_length, petal_width)\n",
    "\n",
    "Print the head, tail of the new dataframe to check things look correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "iris['min_petal']=iris[['petal_length','petal_width']].apply(lambda x: min(x.petal_length, x.petal_width), axis=1)\n",
    "print(iris.head())\n",
    "print(iris.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Aggregation\n",
    "\n",
    "Involves one or more of:\n",
    "\n",
    "- splitting the data into groups\n",
    "- applying a function to each group\n",
    "- combining results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `groupby()`\n",
    "\n",
    "Compute mean of each column, grouped (separately) by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"species\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pivot_table()`\n",
    "\n",
    "Apply a function `aggfunc` to selected values grouped by columns\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute mean sepal length for each species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(iris, values=\"sepal_length\", columns=[\"species\"], aggfunc = np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Use a pivot table to compute the following statistics on sepal_width and petal_width grouped by species:\n",
    "\n",
    "- median  \n",
    "- mean\n",
    "\n",
    "These can be computed together in a single call to `pivot_table()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(iris, values=[\"sepal_width\",\"petal_width\"], columns=[\"species\"], aggfunc = {np.mean, np.median})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Merging/Joining DataFrames\n",
    "\n",
    "\n",
    "### `concat()`  \n",
    "\n",
    "Concatenate pandas objects along an axis\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two dfs and vertically stack them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(3, 4))\n",
    "df2 = pd.DataFrame(np.random.randn(3, 4))\n",
    "\n",
    "print(df1)\n",
    "print('-'*45)\n",
    "print(df2)\n",
    "\n",
    "df3 = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "print('-'*45)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `merge()`\n",
    "\n",
    "SQL-style joining of tables (DataFrames)\n",
    "\n",
    "Important parameters include:\n",
    "\n",
    "- `how` : type of merge {'left', 'right', 'outer', 'inner', 'cross'}, default ‘inner’\n",
    "- `on`  : names to join on\n",
    "        \n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two tables, `left` and `right`. Then right join them on `key`.  \n",
    "Right join means include all records from table on right.  \n",
    "The `key` is used for matching up the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"lval\": [15, 22]})\n",
    "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"rval\": [4, 5, 8]})\n",
    "\n",
    "joined = pd.merge(left, right, on=\"key\", how=\"right\")\n",
    "\n",
    "print('---left')\n",
    "print(left)\n",
    "print('\\n---right')\n",
    "print(right)\n",
    "print('\\n---joined')\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the NaN inserted into the record with key=asher, since the left table didn't contain the key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matching column names**  \n",
    "In this next example, the value columns have the same name: *val*.  Notice what happens to the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"val\": [15, 22]})\n",
    "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"val\": [4, 5, 8]})\n",
    "\n",
    "joined = pd.merge(left, right, on=\"key\", how=\"right\")\n",
    "\n",
    "print('---left')\n",
    "print(left)\n",
    "print('\\n---right')\n",
    "print(right)\n",
    "print('\\n---joined')\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Redo the join exercise above, using an inner join instead of a right join.  \n",
    "Make sure the results make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"lval\": [15, 22]})\n",
    "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"rval\": [4, 5, 8]})\n",
    "\n",
    "joined = pd.merge(left, right, on=\"key\", how=\"inner\")\n",
    "\n",
    "print('---left')\n",
    "print(left)\n",
    "print('\\n---right')\n",
    "print(right)\n",
    "print('\\n---joined')\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add solution and fold to hide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Reshape\n",
    "\n",
    "Changes the object's shape\n",
    "\n",
    "We illustrate creating pandas Series, extracting array of length 6, and reshaping to 3x2 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a series \n",
    "ser = pd.Series([1, 1, 2, 3, 5, 8]) \n",
    "\n",
    "# extract values \n",
    "vals = ser.values \n",
    "\n",
    "print('orig data:', vals)\n",
    "print('orig type:', type(vals))\n",
    "print('orig shape:', vals.shape)\n",
    "\n",
    "# reshaping series\n",
    "reshaped_vals = vals.reshape((3, 2)) \n",
    "\n",
    "print('\\n reshaped vals:')\n",
    "print(reshaped_vals)\n",
    "print('\\n new type:', type(reshaped_vals))\n",
    "print('new shape:', reshaped_vals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including -1 as one of the dimensions tells numpy: infer this dimension from the data and the other dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: enforce 3 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enforce 3 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.reshape(3,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**  \n",
    "\n",
    "Notice the shape of original array: `(6,)`  \n",
    "This is a vector with one dimension, and is different from two-dimensional `(6,1)` array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Recreate the series from above with data [1, 1, 2, 3, 5, 8]  \n",
    "Extract the data from the series and reshape to 2x3.  \n",
    "Print both the reshaped data, and the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series([1, 1, 2, 3, 5, 8])\n",
    "vals= ser.values\n",
    "resh = vals.reshape(2,3)\n",
    "print(resh)\n",
    "print('new shape:', resh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Categoricals\n",
    "\n",
    "Categorical data takes discrete values where computation on the values does not make sense.  \n",
    "Zip code is a typical example.\n",
    "\n",
    "To include categoricals in models, they must be converted to numeric.  \n",
    "\n",
    "### `get_dummies()`\n",
    "Dummy code categorical data\n",
    "\n",
    "Important parameters: \n",
    "\n",
    "- `prefix`    : append prefix to column names (a good idea for later use)\n",
    "- `drop_first`: remove first level, as only `k-1` variables needed to represent `k` levels\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pd.DataFrame({'breed':['persian','persian','siamese','himalayan','burmese']})\n",
    "\n",
    "print('--categorical data')\n",
    "print(cats)\n",
    "\n",
    "cats = pd.get_dummies(cats.breed, drop_first=True, prefix='breed')\n",
    "\n",
    "print('\\n')\n",
    "print('--dummified categorical data')\n",
    "print(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice `burmese` was dropped (first level by alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) The dataframe below contains two categoricals. Dummify each of them, giving them a prefix and dropping the first level from each. \n",
    "\n",
    "Print the new dataframe to insure correctness.\n",
    "\n",
    "Hint: You might want to dummify each column into separate new dataframes, and then merge them together by using:\n",
    "\n",
    "`pd.concat([df1, df2], axis=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats2 = pd.DataFrame({'breed':['persian','persian','siamese','himalayan','burmese'], \n",
    "                      'color':['calico','white','seal point','cream','sable']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cats2 = pd.DataFrame({'breed':['persian','persian','siamese','himalayan','burmese'], \n",
    "                      'color':['calico','white','seal point','cream','sable']})\n",
    "\n",
    "breed = pd.get_dummies(cats2.breed, drop_first=True, prefix='breed_')\n",
    "color = pd.get_dummies(cats2.color, drop_first=True, prefix='color_')\n",
    "\n",
    "cats3 = pd.concat([breed, color], axis=1)\n",
    "cats3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
