{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrames I\n",
    "\n",
    "\n",
    "### Programming for Data Science\n",
    "### Last Updated: Jan 15, 2023\n",
    "---  \n",
    "\n",
    "\n",
    "### PREREQUISITES\n",
    "- variables\n",
    "- data types\n",
    "- operators\n",
    "- list comprehensions (not essential)\n",
    "- numpy arrays (not essential)\n",
    "\n",
    "\n",
    "### SOURCES \n",
    "- ten minutes to pandas  \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "\n",
    "\n",
    "- sort_values()  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "\n",
    "- value_counts()  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html\n",
    "\n",
    "\n",
    "- to_csv() : saving to CSV file  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html\n",
    "\n",
    "\n",
    "- read_csv() : load CSV file into DataFrame  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "\n",
    "\n",
    "- dropna() : drop missing data  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "\n",
    "\n",
    "- fillna() : impute missing data  \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### OBJECTIVES\n",
    "- Introduce pandas dataframes and the essential operations\n",
    " \n",
    "\n",
    "\n",
    "### CONCEPTS\n",
    "\n",
    "- DataFrame\n",
    "- Creating DataFrames\n",
    "- Copy: shallow vs deep\n",
    "- Appending columns\n",
    "- Slicing or subsetting by location, label (name)\n",
    "- Boolean indexing\n",
    "- Sorting\n",
    "- Handling missing data\n",
    "- Statistics\n",
    "\n",
    "---\n",
    "\n",
    "## I. Introduction to Pandas DataFrames\n",
    "\n",
    "Pandas DataFrames were modeled from R Data Frames.\n",
    "\n",
    "- They hold rectangular data (columns are equal length)\n",
    "- Can hold mixed data types, but each column has same type\n",
    "- Contains three attributes:\n",
    "  - index (a column of index values; can use to sort, subset data)\n",
    "  - columns\n",
    "  - values (as a numpy array)\n",
    "\n",
    "Pandas `Series` holds a single column of data.  \n",
    "\n",
    "For shorthand, `df` will refer to pandas DataFrames.  \n",
    "\n",
    "DataFrames can be created with pandas.    \n",
    "Various formats (`csv`,`json`,...) can be loaded into DataFrames.   \n",
    "\n",
    "The [ten minutes to pandas link](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html) above gives a good, brief overview of pandas. Be sure to review.\n",
    "\n",
    "Import pandas like this, where the alias `pd` is convention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Creating DataFrames\n",
    "\n",
    "Several ways to create pandas dataframes\n",
    "\n",
    "- Passing a dictionary of objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, z are lists in the dict\n",
    "\n",
    "df = pd.DataFrame({'x':[0,2,1,5], 'y':[1,1,0,0], 'z':[True,False,False,False]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('attributes of df:')\n",
    "print('index          :', df.index)\n",
    "print('columns        :', df.columns)\n",
    "print('data           :\\n', df.values)\n",
    "print('               ')\n",
    "print('type(df.values):', type(df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passing the three required pieces:\n",
    "  - columns as list\n",
    "  - index as list\n",
    "  - data as list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=['x','y'], index=['row1','row2','row3'], data=[[9,3],[1,2],[4,6]])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Copying DataFrames with `copy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `copy()` to give the new df a clean break from the original.  \n",
    "Otherwise, the copied df will mirror changes in the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deep    = df.copy()  # deep copy; changes to df will not pass through\n",
    "df_shallow = df         # shallow copy; changes to df will pass through\n",
    "\n",
    "print('--df')\n",
    "print(df)\n",
    "\n",
    "# update values in df.x\n",
    "df.x = 1\n",
    "\n",
    "print('--Updated df')\n",
    "print(df)\n",
    "print('--df_shallow')\n",
    "print(df_shallow)\n",
    "print('--df_deep')\n",
    "print(df_deep)\n",
    "\n",
    "# rebuild df\n",
    "df = pd.DataFrame({'x':[0,2,1,5], 'y':[1,1,0,0], 'z':[True,False,False,False]}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice `df_shallow` mirrors changes to `df`, since it references its indices and data.  \n",
    "`df_deep` does not reference `df`, and so changes `to` df do not impact `df_deep`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Show the data type of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Column Renaming\n",
    "\n",
    "Can rename one or more fields at once using a dict.  \n",
    "\n",
    "Rename the field `z` to `is_label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'z':'is_label'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Column Referencing\n",
    "\n",
    "Can use bracket notation or dot notation.  \n",
    "\n",
    "- bracket notation: variable name must be a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dot notation: variable is NOT a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows index and x values\n",
    "\n",
    "df.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show values only (can use dot or bracket notation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show only the first value, by indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List comprehensions are very useful for selecting columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Brief aside on list comprehensions:  \n",
    "- they take a list as input and return a list as output\n",
    "- they transform each element\n",
    "- they can apply one or more filters (if-statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square values in list\n",
    "lst = [1,2,3,4,5]\n",
    "\n",
    "[x**2 for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep odd values from list\n",
    "lst = [1,2,3,4,5]\n",
    "[x for x in lst if x % 2 == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even\n",
    "[x for x in lst if x % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squared evens\n",
    "[x ** 2 for x in lst if x % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain elements containing 'ind'\n",
    "\n",
    "f = ['f1_ind','f2_ind','f3_ind','f1','f2','f3']\n",
    "[x for x in f if 'ind' in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df by selecting columns that are NOT: x, y\n",
    "\n",
    "df3 = df[[col for col in df.columns if col not in ['x','y']]]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df[[col for col in df.columns if col not in ['is_label']]]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Create a dataframe called `dat` by passing a dictionary of inputs. Here are the requirements:\n",
    "- has a column named `features` containing floats\n",
    "- has a column named `labels` containing integers 0, 1, 2  \n",
    "\n",
    "Print the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat = pd.DataFrame({'features':[0.2,-1.1,1.6, 5.4], 'labels':[1,1,0,2]}) \n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Rename the `labels` column in `dat` to `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat = dat.rename(columns={'labels':'label'})\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Appending New Columns\n",
    "\n",
    "It is typical to create a new column from existing columns.  \n",
    "In this example, a new column (or field) is created by summing `x` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_plus_y'] = df.x + df.y\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the components:\n",
    "\n",
    "- the left side has form: DataFrame name, bracket notation, new column name\n",
    "- the assignment operator `=` is used\n",
    "- the right side contains an expression; here, two df columns are summed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bracket notation also works on the fields, but it's more typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_plus_y'] = df['x'] + df['y']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bracket notation must be used when assigning to a new column. This will break:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.'x_plus_y' = df.x + df.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Load Iris Dataset to Illustrate More Functionality\n",
    "\n",
    "The function `load_dataset()` in the `seaborn` package loads the built-in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data type of `iris`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always a good idea to inspect the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first few records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last few records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape (rows, columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alternatively, `len()` returns row (record) count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Subsetting\n",
    "\n",
    "Pandas subsetting is very flexible. The flexibility is useful, but can be confusing.  \n",
    "Regular practice will help.\n",
    "\n",
    "Subsetting (or slicing) a dataframe produces a new dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sepal_length.head()\n",
    "\n",
    "# alternatively,\n",
    "# iris['sepal_length'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract subset of columns, saving into new df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired columns are list of strings\n",
    "\n",
    "lengths = iris[['sepal_length','petal_length']]\n",
    "lengths.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "head() of data, as reminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `iloc()`\n",
    "\n",
    "Extracting rows using **indices** with `iloc()`. This fetches row 3, and all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first few records\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch rows with indices 1,2 (the right endpoint is exclusive), and all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch rows with indices 1,2 and first three columns (positions 0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.iloc[1:3, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first three column names\n",
    "\n",
    "iris.columns[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `loc()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsetting on a df can also be done with `loc()`. This uses the row, column labels (names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we ask for rows with labels (indexes) 1-3, and it gives exactly that  \n",
    "`iloc()` returned rows with indices 1,2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset on columns with column name (as a string) or list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[1:3, ['sepal_length','petal_width']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all rows, specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[:, ['sepal_length','petal_width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.DataFrame(index=['burmese','persian','maine_coone'],columns=['x'],data=[2,1,3])\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.loc['burmese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.loc[['burmese','maine_coone']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing: Subsetting based on Conditions\n",
    "\n",
    "It's very common to subset a dataframe based on some condition on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean mask\n",
    "\n",
    "iris.sepal_length >= 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[iris.sepal_length >= 7.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple conditions\n",
    "\n",
    "iris[(iris['sepal_length']>=4.5) & (iris['sepal_length']<=4.7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrate the `Boolean mask` by assigning earlier condition to variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the sepal_length values\n",
    "\n",
    "iris.sepal_length.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the mask and show the bool values\n",
    "\n",
    "mask = iris.sepal_length >= 7.5\n",
    "mask.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the True values\n",
    "\n",
    "iris.sepal_length[mask].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the mask will return True/False for each value.  \n",
    "Subsetting on the mask will return only the values where mask value is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Working with Missing Data\n",
    "\n",
    "Pandas primarily uses np.nan (from `numpy`) to represent missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_miss = pd.DataFrame({'x':[2, np.nan, 1], 'y':[np.nan, np.nan, 6]})\n",
    "df_miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`dropna()` will drop missing**\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all missing data\n",
    "\n",
    "df_drop_all = df_miss.dropna()\n",
    "df_drop_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records where column: x has np.nan\n",
    "\n",
    "df_drop_x = df_miss.dropna(subset=['x'])\n",
    "df_drop_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`fillna()` fills missing**\n",
    "\n",
    "Can fill with values, statistic. \n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)\n",
    "\n",
    "Example to impute each column with its median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df_miss.fillna(df_miss.median())\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XI. Sorting\n",
    "\n",
    "Sort by values\n",
    "- `by` parameter takes string or list of strings\n",
    "- `ascending` takes True or False\n",
    "- `inplace` will save sorted values into the df\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sort_values(by=['sepal_length','petal_width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by index. Example sorts by descending index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sort_index(axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XII. Statistical Summary of a DataFrame using `describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.species.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sepal_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XIII. Column Frequency using `value_counts()`\n",
    "\n",
    "This is a highly useful function for showing the frequency for each distinct value.  \n",
    "Parameters give the ability to sort by count or index, normalize, and more.  \n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show percentages instead of counts\n",
    "\n",
    "iris.species.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XIV. Statistics\n",
    "\n",
    "Operations generally exclude missing data.\n",
    "\n",
    "Some of the stats are shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sepal_length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sepal_length.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation\n",
    "\n",
    "iris.sepal_length.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation (default=pearson) can be computed on two fields by subsetting on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[['sepal_length','petal_length']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr on three columns\n",
    "\n",
    "iris[['sepal_length','petal_length','sepal_width']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full correlation matrix\n",
    "\n",
    "iris.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XV. Visualization\n",
    "\n",
    "Scatterplot using `seaborn` on the df columns `sepal_length`, `petal_length`.\n",
    "\n",
    "Visualization will be covered separately in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.scatterplot(x=iris.sepal_length, y=iris.petal_length)\n",
    "fig.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XVI. Save to CSV File\n",
    "\n",
    "Common to save df to a csv file. The full path (path + filename) is required.  \n",
    "\n",
    "Common optional parameters:\n",
    "- `sep` - delimiter\n",
    "- `index` - saving index column or not\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.to_csv('./iris_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XVII. Deleting (Dropping) Columns\n",
    "\n",
    "`del` can drop a DataFrame or single columns from the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del iris['sepal_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`drop()` can drop one or more columns\n",
    "\n",
    "takes `axis` parameter:\n",
    "- axis=0 refers to rows  \n",
    "- axis=1 refers to columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.drop(['sepal_length', 'species'], axis=1)\n",
    "iris.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XVIII. Read from CSV File\n",
    "\n",
    "`read_csv()` reads from csv into DataFrame\n",
    "\n",
    "takes full filepath\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_loaded = pd.read_csv('./iris_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_loaded.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY FOR YOURSELF (UNGRADED EXERCISES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Sort the iris dataset by species, descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_sort = iris.sort_values(by=['species'], ascending=False)\n",
    "iris_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Filter the iris dataset to show only species='setosa', and save to df called `setosa`.  \n",
    "Next, call the `value_counts()` function on `setosa.species` to show the only species in the df is setosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "setosa = iris[iris.species=='setosa']\n",
    "setosa.species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Print the number of records in iris where petal_length <= 1.4 or petal_length >= 1.6  \n",
    "Hint1: check how to implement \"or\" in pandas  \n",
    "Hint2: subset using boolean indexing, and count the number of resulting records with `len()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(iris[(iris.petal_length <= 1.4) | (iris.petal_length >= 1.6)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
